{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb84e3fd-0b7d-42aa-8145-ebef7b632101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|CO   |Blue  |1695 |\n",
      "|WY   |Green |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1673 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1663 |\n",
      "|WA   |Orange|1658 |\n",
      "|CA   |Orange|1657 |\n",
      "|NV   |Brown |1657 |\n",
      "|CO   |Brown |1656 |\n",
      "|CA   |Red   |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1646 |\n",
      "|UT   |Yellow|1645 |\n",
      "|OR   |Red   |1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|TX   |Blue  |1614 |\n",
      "|OR   |Yellow|1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 60\n",
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|CA   |Green |1723 |\n",
      "|CA   |Brown |1718 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CA   |Blue  |1603 |\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Build a SparkSession using the SparkSession APIs.\n",
    "# If one does not exist, then create an instance. There\n",
    "# can only be one SparkSession per JVM.\n",
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"PythonMnMCount\")\n",
    " .getOrCreate())\n",
    "\n",
    "# Get the M&M data set filename from the command-line arguments\n",
    "mnm_file = \"C:/Users/alejandro.perez/Documents/LearningSparkV2-master/chapter2/py/src/data/mnm_dataset.csv\"\n",
    " # Read the file into a Spark DataFrame using the CSV\n",
    " # format by inferring the schema and specifying that the\n",
    " # file contains a header, which provides column names for comma-\n",
    " # separated fields.\n",
    "\n",
    "mnm_df = (spark.read.format(\"csv\")\n",
    " .option(\"header\", \"true\")\n",
    " .option(\"inferSchema\", \"true\")\n",
    " .load(mnm_file))\n",
    " # We use the DataFrame high-level APIs. Note\n",
    " # that we don't use RDDs at all. Because some of Spark's \n",
    " # functions return the same object, we can chain function calls.\n",
    " # 1. Select from the DataFrame the fields \"State\", \"Color\", and \"Count\"\n",
    " # 2. Since we want to group each state and its M&M color count,\n",
    " # we use groupBy()\n",
    " # 3. Aggregate counts of all colors and groupBy() State and Color\n",
    " # 4 orderBy() in descending order\n",
    "\n",
    "mnm_df.printSchema()\n",
    "\n",
    "count_mnm_df = (mnm_df\n",
    " .select(\"State\", \"Color\", \"Count\")\n",
    " .groupBy(\"State\", \"Color\")\n",
    " .agg(count(\"Count\").alias(\"Total\"))\n",
    " .orderBy(\"Total\", ascending=False))\n",
    " # Show the resulting aggregations for all the states and colors;\n",
    " # a total count of each color per state.\n",
    " # Note show() is an action, which will trigger the above\n",
    " # query to be executed.\n",
    "\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))\n",
    "\n",
    "# While the above code aggregated and counted for all \n",
    "# the states, what if we just want to see the data for \n",
    "# a single state, e.g., CA? \n",
    "# 1. Select from all rows in the DataFrame\n",
    "# 2. Filter only CA state\n",
    "# 3. groupBy() State and Color as we did above\n",
    "# 4. Aggregate the counts for each color\n",
    "# 5. orderBy() in descending order \n",
    "\n",
    "# Find the aggregate count for California by filtering\n",
    "ca_count_mnm_df = (mnm_df\n",
    " .select(\"State\", \"Color\", \"Count\")\n",
    " .where(mnm_df.State == \"CA\")\n",
    " .groupBy(\"State\", \"Color\")\n",
    " .agg(count(\"Count\").alias(\"Total\"))\n",
    " .orderBy(\"Total\", ascending=False))\n",
    "\n",
    "# Show the resulting aggregation for California.\n",
    "# As above, show() is an action that will trigger the execution of the\n",
    "# entire computation. \n",
    "\n",
    "ca_count_mnm_df.show(n=10, truncate=False)\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4e7a0-7adc-4ecc-8092-938aac862631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9122dc0f-135a-4cac-b20f-594b18444e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|WY   |Green |1695 |\n",
      "|CO   |Blue  |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1673 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1663 |\n",
      "|WA   |Orange|1658 |\n",
      "|CA   |Orange|1657 |\n",
      "|NV   |Brown |1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CO   |Brown |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1646 |\n",
      "|OR   |Red   |1645 |\n",
      "|UT   |Yellow|1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|TX   |Blue  |1614 |\n",
      "|OR   |Yellow|1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 60\n",
      "+-----+------+------+\n",
      "|State|Color |Total |\n",
      "+-----+------+------+\n",
      "|CA   |Yellow|100956|\n",
      "|CA   |Brown |95762 |\n",
      "|CA   |Green |93505 |\n",
      "|CA   |Red   |91527 |\n",
      "|CA   |Orange|90311 |\n",
      "|CA   |Blue  |89123 |\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"PythonMnMCount\")\n",
    " .getOrCreate())\n",
    "\n",
    "# Get the M&M data set filename from the command-line arguments\n",
    "mnm_file = \"C:/Users/alejandro.perez/Documents/LearningSparkV2-master/chapter2/py/src/data/mnm_dataset.csv\"\n",
    " # Read the file into a Spark DataFrame using the CSV\n",
    " # format by inferring the schema and specifying that the\n",
    " # file contains a header, which provides column names for comma-\n",
    " # separated fields.\n",
    "\n",
    "mnm_df = (spark.read.format(\"csv\")\n",
    " .option(\"header\", \"true\")\n",
    " .option(\"inferSchema\", \"true\")\n",
    " .load(mnm_file))\n",
    " # We use the DataFrame high-level APIs. Note\n",
    " # that we don't use RDDs at all. Because some of Spark's \n",
    " # functions return the same object, we can chain function calls.\n",
    " # 1. Select from the DataFrame the fields \"State\", \"Color\", and \"Count\"\n",
    " # 2. Since we want to group each state and its M&M color count,\n",
    " # we use groupBy()\n",
    " # 3. Aggregate counts of all colors and groupBy() State and Color\n",
    " # 4 orderBy() in descending order\n",
    "count_mnm_df = (mnm_df\n",
    " .select(\"State\", \"Color\", \"Count\")\n",
    " .groupBy(\"State\", \"Color\")\n",
    " .agg(count(\"Count\").alias(\"Total\"))\n",
    " .orderBy(\"Total\", ascending=False))\n",
    " # Show the resulting aggregations for all the states and colors;\n",
    " # a total count of each color per state.\n",
    " # Note show() is an action, which will trigger the above\n",
    " # query to be executed.\n",
    "\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))\n",
    "\n",
    "# While the above code aggregated and counted for all \n",
    "# the states, what if we just want to see the data for \n",
    "# a single state, e.g., CA? \n",
    "# 1. Select from all rows in the DataFrame\n",
    "# 2. Filter only CA state\n",
    "# 3. groupBy() State and Color as we did above\n",
    "# 4. Aggregate the counts for each color\n",
    "# 5. orderBy() in descending order \n",
    "\n",
    "# Find the aggregate count for California by filtering\n",
    "ca_count_mnm_df = (mnm_df\n",
    " .select(\"State\", \"Color\", \"Count\")\n",
    " .where(mnm_df.State == \"CA\")\n",
    " .groupBy(\"State\", \"Color\")\n",
    " .agg(sum(\"Count\").alias(\"Total\"))\n",
    " .orderBy(\"Total\", ascending=False))\n",
    "\n",
    "# Show the resulting aggregation for California.\n",
    "# As above, show() is an action that will trigger the execution of the\n",
    "# entire computation. \n",
    "\n",
    "ca_count_mnm_df.show(n=10, truncate=False)\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07e7de-e850-445a-bd24-b265117676fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
